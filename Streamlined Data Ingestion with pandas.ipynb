{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3yoHPA7Ke47qS92Lmpt0y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmalaraj77/Python/blob/main/Streamlined%20Data%20Ingestion%20with%20pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Streamlined Data Ingestion with pandas**\n"
      ],
      "metadata": {
        "id": "AP6li-VVaAZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Notes**\n",
        "\n",
        "### **Plot the total number of tax returns by income group**\n",
        "* counts = data.groupby(\"agi_stub\").N1.sum()\n",
        "* counts.plot.bar()\n",
        "* plt.show()\n",
        "\n",
        "### **View counts of dependents and tax returns by income level**\n",
        "* print(data.groupby(\"agi_stub\").sum())\n",
        "\n",
        "### **check if 2 dfs are equal**\n",
        "* tax_data_v1.equals(tax_data_v2)\n",
        "\n",
        "###**find data with NA values**\n",
        "* print(tax_data[tax_data.zipcode.isna()])\n",
        "\n"
      ],
      "metadata": {
        "id": "wnO2HUkJdeIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Flat Files**\n",
        "* Load pandas\n",
        "* Import files\n",
        "* Use sep = '\\t' for TSV\n"
      ],
      "metadata": {
        "id": "JZHQ_r8KapMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rOJUkLBbZcs5"
      },
      "outputs": [],
      "source": [
        "#  load pandas and df\n",
        "import pandas as pd\n",
        "\n",
        "vermont_url = 'https://assets.datacamp.com/production/repositories/4412/datasets/61bb27bf939aac4344d4f446ce6da1d1bf534174/vt_tax_data_2016.csv'\n",
        "free_code_camp_url = 'https://assets.datacamp.com/production/repositories/4412/datasets/fdb113aa942a0e0ad5c155b2f04784886f0038c9/fcc-new-coder-survey.xlsx'\n",
        "nyc_weather_url = 'https://github.com/nirmalaraj77/datasets/blob/main/data.db'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modify flat file imports**\n",
        "\n",
        "### **limit columns - usecols**\n",
        "* accepts list of col numbers, names or function\n",
        "\n",
        "### **limit rows - nrows and skiprows**\n",
        "* accepts list of row numbers, number of rows or function\n",
        "* set header =None so pandas knows there are no column names\n",
        "* get rows 1000 to 1500\n",
        "* df = pd.read_csv ('xxx.csv', nrows = 1000, skiprows = 1000, header=None)\n",
        "\n",
        "### **assign column names**\n",
        "* names argument\n",
        "* list MUST include name for every column\n",
        "* can get list from previous df to reuse -> col_names = list(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkpwYlHgelD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load vermont db\n",
        "import pandas as pd\n",
        "vermont = pd.read_csv(vermont_url)\n",
        "\n",
        "# find shape\n",
        "print(vermont.shape)\n",
        "\n",
        "# get col names\n",
        "col_names = list(vermont)\n",
        "print(col_names)\n",
        "\n",
        "# load 1000 - 1250 rows with column names\n",
        "vermont_1000_1250 = pd.read_csv(vermont_url, nrows = 251, skiprows = 1000, header=None, names = col_names)\n",
        "print(vermont_1000_1250.head())\n",
        "\n",
        "# print dtypes\n",
        "print(vermont_1000_1250.dtypes)\n"
      ],
      "metadata": {
        "id": "gvJPMnbmmE3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Error Handling**\n",
        "\n",
        "###**Specify data types**\n",
        "\n",
        "* dtype - takes dictionary of column name and date type\n",
        "* non-standard dtypes like pandas categories must be passed in quotations\n",
        "\n",
        "###**Customize missing data values**\n",
        "\n",
        "* na_values - takes single value, list or dict of colmns and values\n",
        "\n",
        "###**Lines with errors**\n",
        "\n",
        "* try - except\n",
        "* error_bad_lines=False - skip unparsable records\n",
        "* warn_bad_lines=True - see messages when records are skipped\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NWxwOP6Uo1Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find vermont dtypes\n",
        "print(vermont.dtypes)\n",
        "\n",
        "# set dict to change zipcode and agi_stub columns dtypes\n",
        "data_types = {'agi_stub':'category',\n",
        "\t\t\t  'zipcode' : 'str'}\n",
        "\n",
        "# load vermont csv specifying types\n",
        "vermont = pd.read_csv(vermont_url, dtype = data_types)\n",
        "\n",
        "# find vermont dtypes again\n",
        "print(vermont.dtypes.head())"
      ],
      "metadata": {
        "id": "0Dtsh42i206K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dict specifying that 0s in zipcode are NA values\n",
        "null_values = {'zipcode': 0}\n",
        "\n",
        "# Load csv using na_values keyword argument\n",
        "vermont = pd.read_csv(vermont_url,\n",
        "                   na_values = null_values)\n",
        "\n",
        "# View rows with NA ZIP codes\n",
        "print(vermont[vermont.zipcode.isna()])"
      ],
      "metadata": {
        "id": "GgT2OD8t5ner"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  # Set warn_bad_lines to issue warnings about bad records\n",
        "  data = pd.read_csv(\"vt_tax_data_2016_corrupt.csv\",\n",
        "                     error_bad_lines=False,\n",
        "                     warn_bad_lines=True)\n",
        "\n",
        "  # View first 5 records\n",
        "  print(data.head())\n",
        "\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Your data contained rows that could not be parsed.\")"
      ],
      "metadata": {
        "id": "oxDxf5yO93n8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}