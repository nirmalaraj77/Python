{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyaCBhro+eJfpQURRiV1DV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmalaraj77/Python/blob/main/Streamlined%20Data%20Ingestion%20with%20pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Streamlined Data Ingestion with pandas**\n"
      ],
      "metadata": {
        "id": "AP6li-VVaAZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Notes**\n",
        "\n",
        "### **Plot the total number of tax returns by income group**\n",
        "* counts = data.groupby(\"agi_stub\").N1.sum()\n",
        "* counts.plot.bar()\n",
        "* plt.show()\n",
        "\n",
        "### **View counts of dependents and tax returns by income level**\n",
        "* print(data.groupby(\"agi_stub\").sum())\n",
        "\n",
        "### **check if 2 dfs are equal**\n",
        "* tax_data_v1.equals(tax_data_v2)\n",
        "\n",
        "###**find data with NA values**\n",
        "* print(tax_data[tax_data.zipcode.isna()])\n",
        "\n",
        "### **View Unique years in data**\n",
        "* print(all_responses.Year.unique())\n",
        "\n",
        "### **Graph where people would like to get a developer job**\n",
        "* job_prefs = responses_2017.groupby(\"JobPref\").JobPref.count()\n",
        "* job_prefs.plot.barh()\n",
        "* plt.show()\n",
        "\n",
        "### **Count true values**\n",
        "* df.sum()\n",
        "\n",
        "### **Count NAs**\n",
        "* df.isna().sum()\n",
        "\n",
        "### **Print first few values of Part1StartTime**\n",
        "* print(survey_data.Part1StartTime.head())\n",
        "\n",
        "### **Printing the dataframe's column names**\n",
        "* print(list(df_name))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wnO2HUkJdeIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rOJUkLBbZcs5"
      },
      "outputs": [],
      "source": [
        "#  load pandas and df\n",
        "import pandas as pd\n",
        "\n",
        "vermont_url = 'https://assets.datacamp.com/production/repositories/4412/datasets/61bb27bf939aac4344d4f446ce6da1d1bf534174/vt_tax_data_2016.csv'\n",
        "free_code_camp_url = 'https://assets.datacamp.com/production/repositories/4412/datasets/fdb113aa942a0e0ad5c155b2f04784886f0038c9/fcc-new-coder-survey.xlsx'\n",
        "nyc_weather_url = 'https://github.com/nirmalaraj77/datasets/blob/main/data.db'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**CSV and TSV Flat Files**\n",
        "* Load pandas\n",
        "* Import files\n",
        "* Use sep = '\\t' for TSV\n"
      ],
      "metadata": {
        "id": "JZHQ_r8KapMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modify flat file imports**\n",
        "\n",
        "### **limit columns - usecols**\n",
        "* accepts list of col numbers, names or function\n",
        "\n",
        "### **limit rows - nrows and skiprows**\n",
        "* accepts list of row numbers, number of rows or function\n",
        "* set header =None so pandas knows there are no column names\n",
        "* get rows 1000 to 1500\n",
        "* df = pd.read_csv ('xxx.csv', nrows = 1000, skiprows = 1000, header=None)\n",
        "\n",
        "### **assign column names**\n",
        "* names argument\n",
        "* list MUST include name for every column\n",
        "* can get list from previous df to reuse -> col_names = list(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkpwYlHgelD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load vermont db\n",
        "import pandas as pd\n",
        "vermont = pd.read_csv(vermont_url)\n",
        "\n",
        "# find shape\n",
        "print(vermont.shape)\n",
        "\n",
        "# get col names\n",
        "col_names = list(vermont)\n",
        "print(col_names)\n",
        "\n",
        "# load 1000 - 1250 rows with column names\n",
        "vermont_1000_1250 = pd.read_csv(vermont_url, nrows = 251, skiprows = 1000, header=None, names = col_names)\n",
        "print(vermont_1000_1250.head())\n",
        "\n",
        "# print dtypes\n",
        "print(vermont_1000_1250.dtypes)"
      ],
      "metadata": {
        "id": "gvJPMnbmmE3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ec8fbc-2ebe-4a27-bdd4-2c2c8ec369ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1476, 147)\n",
            "['STATEFIPS', 'STATE', 'zipcode', 'agi_stub', 'N1', 'mars1', 'MARS2', 'MARS4', 'PREP', 'N2', 'NUMDEP', 'TOTAL_VITA', 'VITA', 'TCE', 'VITA_EIC', 'RAL', 'RAC', 'ELDERLY', 'A00100', 'N02650', 'A02650', 'N00200', 'A00200', 'N00300', 'A00300', 'N00600', 'A00600', 'N00650', 'A00650', 'N00700', 'A00700', 'N00900', 'A00900', 'N01000', 'A01000', 'N01400', 'A01400', 'N01700', 'A01700', 'SCHF', 'N02300', 'A02300', 'N02500', 'A02500', 'N26270', 'A26270', 'N02900', 'A02900', 'N03220', 'A03220', 'N03300', 'A03300', 'N03270', 'A03270', 'N03150', 'A03150', 'N03210', 'A03210', 'N03230', 'A03230', 'N03240', 'A03240', 'N04470', 'A04470', 'A00101', 'N17000', 'A17000', 'N18425', 'A18425', 'N18450', 'A18450', 'N18500', 'A18500', 'N18800', 'A18800', 'N18300', 'A18300', 'N19300', 'A19300', 'N19500', 'A19500', 'N19530', 'A19530', 'N19550', 'A19550', 'N19570', 'A19570', 'N19700', 'A19700', 'N20800', 'A20800', 'n21020', 'a21020', 'N04800', 'A04800', 'N05800', 'A05800', 'N09600', 'A09600', 'N05780', 'A05780', 'N07100', 'A07100', 'N07300', 'A07300', 'N07180', 'A07180', 'N07230', 'A07230', 'N07240', 'A07240', 'N07220', 'A07220', 'N07260', 'A07260', 'N09400', 'A09400', 'N85770', 'A85770', 'N85775', 'A85775', 'N09750', 'A09750', 'N10600', 'A10600', 'N59660', 'A59660', 'N59720', 'A59720', 'N11070', 'A11070', 'N10960', 'A10960', 'N11560', 'A11560', 'N06500', 'A06500', 'N10300', 'A10300', 'N85530', 'A85530', 'N85300', 'A85300', 'N11901', 'A11901', 'N11902', 'A11902']\n",
            "   STATEFIPS STATE  zipcode  agi_stub   N1  mars1  MARS2  MARS4  PREP   N2  \\\n",
            "0         50    VT     5730         4   20      0      0      0    40   40   \n",
            "1         50    VT     5730         5   30      0     30      0     0   70   \n",
            "2         50    VT     5730         6    0      0      0      0     0    0   \n",
            "3         50    VT     5732         1  200    150     30     30   100  260   \n",
            "4         50    VT     5732         2  120     70     30      0    60  200   \n",
            "\n",
            "   ...  N10300  A10300  N85530  A85530  N85300  A85300  N11901  A11901  \\\n",
            "0  ...       0       0       0       0       0       0       0       0   \n",
            "1  ...      30    1046       0       0       0       0       0       0   \n",
            "2  ...       0       0       0       0       0       0       0       0   \n",
            "3  ...     110     104       0       0       0       0      20      20   \n",
            "4  ...     110     294       0       0       0       0       0       0   \n",
            "\n",
            "   N11902  A11902  \n",
            "0       0       0  \n",
            "1      20      71  \n",
            "2       0       0  \n",
            "3     160     250  \n",
            "4     110     215  \n",
            "\n",
            "[5 rows x 147 columns]\n",
            "STATEFIPS     int64\n",
            "STATE        object\n",
            "zipcode       int64\n",
            "agi_stub      int64\n",
            "N1            int64\n",
            "              ...  \n",
            "A85300        int64\n",
            "N11901        int64\n",
            "A11901        int64\n",
            "N11902        int64\n",
            "A11902        int64\n",
            "Length: 147, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Error Handling**\n",
        "\n",
        "###**Specify data types**\n",
        "\n",
        "* dtype - takes dictionary of column name and data type\n",
        "* non-standard dtypes like pandas categories must be passed in quotations\n",
        "\n",
        "###**Customize missing data values**\n",
        "\n",
        "* na_values - takes single value, list or dict of colmns and values\n",
        "\n",
        "###**Lines with errors**\n",
        "\n",
        "* try - except\n",
        "* error_bad_lines=False - skip unparsable records\n",
        "* warn_bad_lines=True - see messages when records are skipped\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NWxwOP6Uo1Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find vermont dtypes\n",
        "print(vermont.dtypes)\n",
        "\n",
        "# set dict to change zipcode and agi_stub columns dtypes\n",
        "data_types = {'agi_stub':'category',\n",
        "\t\t\t  'zipcode' : 'str'}\n",
        "\n",
        "# load vermont csv specifying types\n",
        "vermont = pd.read_csv(vermont_url, dtype = data_types)\n",
        "\n",
        "# find vermont dtypes again\n",
        "print(vermont.dtypes.head())"
      ],
      "metadata": {
        "id": "0Dtsh42i206K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dict specifying that 0s in zipcode are NA values\n",
        "null_values = {'zipcode': 0}\n",
        "\n",
        "# Load csv using na_values keyword argument\n",
        "vermont = pd.read_csv(vermont_url,\n",
        "                   na_values = null_values)\n",
        "\n",
        "# View rows with NA ZIP codes\n",
        "print(vermont[vermont.zipcode.isna()])"
      ],
      "metadata": {
        "id": "GgT2OD8t5ner"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  # Set warn_bad_lines to issue warnings about bad records\n",
        "  data = pd.read_csv(\"vt_tax_data_2016_corrupt.csv\",\n",
        "                     error_bad_lines=False,\n",
        "                     warn_bad_lines=True)\n",
        "\n",
        "  # View first 5 records\n",
        "  print(data.head())\n",
        "\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Your data contained rows that could not be parsed.\")"
      ],
      "metadata": {
        "id": "oxDxf5yO93n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Excel Files**\n",
        "\n",
        "* pd.read_excel\n",
        "* nrows\n",
        "* skiprows\n",
        "* usecols - name, positional number,function or letter (e.g. A:P)\n",
        "\n",
        "\n",
        "###**Multiple Sheets**\n",
        "\n",
        "* sheet_name - string, 0 indexed position numbers, list\n",
        "* any other arguments apply to all sheets\n",
        "\n",
        "\n",
        "###**Load all sheets**\n",
        "\n",
        "* sheet_name=None - outputs dictionary\n",
        "* keys - sheet names\n",
        "* values  - dataframes for each sheet\n",
        "* create empty df and itearte through dict\n",
        "* add columns for keys\n",
        "* add dict to concat function\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1cio6BVDxXc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "col_string = 'A:H'\n",
        "data_types = {'A': 'int64'}\n",
        "\n",
        "survey_data = pd.read_excel(free_code_camp_url,\n",
        "                            skiprows=2,\n",
        "                            usecols=col_string)\n",
        "\n",
        "survey_data.head(1)"
      ],
      "metadata": {
        "id": "g2ZuZv8Mxd0g",
        "outputId": "89fe60ec-22cc-407e-adac-c567533551df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
              "0  28.0               0.0             NaN                NaN          NaN   \n",
              "\n",
              "   BootcampRecommend  ChildrenNumber                 CityPopulation  \n",
              "0                NaN             NaN  between 100,000 and 1 million  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b5a0469-1af8-4981-b7be-2fd75403874f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>AttendedBootcamp</th>\n",
              "      <th>BootcampFinish</th>\n",
              "      <th>BootcampLoanYesNo</th>\n",
              "      <th>BootcampName</th>\n",
              "      <th>BootcampRecommend</th>\n",
              "      <th>ChildrenNumber</th>\n",
              "      <th>CityPopulation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>between 100,000 and 1 million</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b5a0469-1af8-4981-b7be-2fd75403874f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b5a0469-1af8-4981-b7be-2fd75403874f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b5a0469-1af8-4981-b7be-2fd75403874f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "survey_data",
              "summary": "{\n  \"name\": \"survey_data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.039495634389729,\n        \"min\": 14.0,\n        \"max\": 80.0,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          21.0,\n          56.0,\n          75.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AttendedBootcamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18940394238836844,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BootcampFinish\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4970501217477085,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BootcampLoanYesNo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49441323247304414,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BootcampName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Codify Academy\",\n          \"Flatiron School\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BootcampRecommend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45425676257949804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ChildrenNumber\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.050133170823533,\n        \"min\": 1.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CityPopulation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"between 100,000 and 1 million\",\n          \"more than 1 million\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load sheet 1 with index no.\n",
        "survey_data_sheet1 = pd.read_excel(free_code_camp_url,\n",
        "                                   sheet_name=1)\n",
        "\n",
        "# load sheet 2 with name\n",
        "survey_data_sheet2 = pd.read_excel(free_code_camp_url,\n",
        "                                   sheet_name='2017')\n",
        "\n",
        "# check if they are equal\n",
        "print(survey_data_sheet1.equals(survey_data_sheet2))"
      ],
      "metadata": {
        "id": "QghG7KbXDfAY",
        "outputId": "2a356c49-8d52-4105-e4c5-2211bc6bd4cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load all sheets\n",
        "survey_data_all = pd.read_excel(free_code_camp_url,\n",
        "                               sheet_name=None)\n",
        "\n",
        "# check type\n",
        "print(type(survey_data_all))\n",
        "\n",
        "# iterate over dict\n",
        "for key, value in survey_data_all.items():\n",
        "  print(key, type(value))\n",
        "\n",
        "# create empty df\n",
        "all_responses = pd.DataFrame()\n",
        "\n",
        "# iterate through dictionary\n",
        "for sheet_name , frame in survey_data_all.items():\n",
        "  # add column so we know which year data id from\n",
        "  frame[\"Year\"] = sheet_name\n",
        "\n",
        "  # add the dataframe to all responses\n",
        "  all_responses = pd.concat([all_responses, frame])\n",
        "\n",
        "# View years in data\n",
        "print(all_responses.Year.unique())\n",
        "print(all_responses.head(1))\n",
        "\n"
      ],
      "metadata": {
        "id": "696x3b_pzfxy",
        "outputId": "d9185397-1e1d-4d81-b5a5-be029963c6c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "2016 <class 'pandas.core.frame.DataFrame'>\n",
            "2017 <class 'pandas.core.frame.DataFrame'>\n",
            "['2016' '2017']\n",
            "   FreeCodeCamp New Developer Survey Responses, 2016 Unnamed: 1 Unnamed: 2  \\\n",
            "0  Source: https://www.kaggle.com/freecodecamp/20...        NaN        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
            "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "\n",
            "  Unnamed: 9  ... Unnamed: 90 Unnamed: 91 Unnamed: 92 Unnamed: 93 Unnamed: 94  \\\n",
            "0        NaN  ...         NaN         NaN         NaN         NaN         NaN   \n",
            "\n",
            "  Unnamed: 95 Unnamed: 96 Unnamed: 97  Year  \\\n",
            "0         NaN         NaN         NaN  2016   \n",
            "\n",
            "  FreeCodeCamp New Developer Survey Responses, 2017  \n",
            "0                                               NaN  \n",
            "\n",
            "[1 rows x 100 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modifiying Imports: True / false data**\n",
        "* **pandas automatically recognizes \"TRUE\" and 1, as True | \"FALSE\" and 0, as False**\n",
        "* **Some datasets (survey data) can use unrecognized values, \"Yes\" and \"No\"**\n",
        "* Datasets may have columns that are most accurately modeled as Boolean values\n",
        "* However, pandas usually loads these as floats by default\n",
        "* Since defaulting to Booleans may have undesired effect - like turning NA values into Trues\n",
        "* **If you want to make a column with NA values Boolean, you can load the data, impute missing values, then re-cast the column as Boolean**\n",
        "\n",
        "###**Customising True / False**\n",
        "* dtype - Bool\n",
        "* true_values = ['Yes'] - custom True values\n",
        "* false_values = ['No'] - custom False values\n",
        "* takes list of values to treat as True / False\n",
        "* non Boolean columns not converted\n",
        "\n",
        "###**Boolean considerations**\n",
        "* are there missing values now or in future\n",
        "* how will this column be used in analysis\n",
        "* what would hapen if a value were incorrecly coded as True\n",
        "* could data be modelled as floats or integers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7E79FaTLcAlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Modifying Imports: Parsing Dates**\n",
        "\n",
        "* datetime data type\n",
        "* can be translated to string representations\n",
        "* datetime columns are loaded as objects (strings) by default\n",
        "* parse_dates - accepts:\n",
        "  * a list of column names or numbers\n",
        "  * a list containing lists of columns to combine and parse\n",
        "  * a dictionary where keys are new column names and values are lists of columns to parse together\n",
        "\n",
        "### **Non-standard dates**\n",
        "* pd.to_datetime()\n",
        "* dataframe and column\n",
        "* format - string representation of datetime format\n",
        "* %Y year 1999\n",
        "* *%m month 03\n",
        "* %d date 01\n",
        "* %H hour 21\n",
        "* %M minute 09\n",
        "* %S second 05\n",
        "\n",
        "### **Parsing non-standard dates**\n",
        "* E.g. 03292016 21:27:25\n",
        "* format_string = \"%m%d%Y  %H:%M:%S\"\n",
        "* df_name['col_name'] = pd.to_datetime(df_name['col_name'], format = format_string\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fH3W7SXPoQn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load file, with Part1StartTime parsed as datetime data\n",
        "survey_data = pd.read_excel(free_code_camp_url,skiprows=2,\n",
        "                            parse_dates = ['Part1StartTime'])\n",
        "\n",
        "# Print first few values of Part1StartTime\n",
        "print(survey_data.Part1StartTime.head())"
      ],
      "metadata": {
        "id": "vM1buZUy_1E4",
        "outputId": "c46610d7-d9c2-4159-b5ad-1f86642c69bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   2016-03-29 21:23:13\n",
            "1   2016-03-29 21:24:59\n",
            "2   2016-03-29 21:25:37\n",
            "3   2016-03-29 21:21:37\n",
            "4   2016-03-29 21:26:22\n",
            "Name: Part1StartTime, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load file, with Part1StartTime parsed as datetime data\n",
        "survey_data = pd.read_excel(free_code_camp_url,skiprows=2)\n",
        "\n",
        "# Parse datetimes and assign result back to Part2EndTime\n",
        "survey_data[\"Part2EndTime\"] = pd.to_datetime(survey_data[\"Part2EndTime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Print first few values of Part2EndTime\n",
        "print(survey_data.Part2EndTime.head())"
      ],
      "metadata": {
        "id": "z-tzUYZWCeF-",
        "outputId": "5c947e11-580d-4781-dcf5-34e5aa826a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   2016-03-29 21:27:25\n",
            "1   2016-03-29 21:29:10\n",
            "2   2016-03-29 21:28:21\n",
            "3   2016-03-29 21:30:51\n",
            "4   2016-03-29 21:31:54\n",
            "Name: Part2EndTime, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Databases**\n",
        "\n",
        "### **Connect to database**\n",
        "* SQLite sqlalchemy library\n",
        "* from sqlalchemy import create_engine()\n",
        "  * string url\n",
        "  * SqLite URL format: sqlite:///filename.db\n",
        "\n",
        "### **Query database**\n",
        "* pd.read_sql(query, engine)\n",
        "  * query: String containing SL query or table to load\n",
        "  * engine: Connection / database engine object\n",
        "\n",
        "### **Load and Query a sample database**\n",
        "#### load pandas and sqlalchemy create_engine\n",
        "* import pandas as pd\n",
        "* from sqlalchemy import create_engine\n",
        "\n",
        "#### Create the database engine to manage connections\n",
        "* engine = create_engine('sqlite:///data.db')\n",
        "\n",
        "#### load entire weather table by table name\n",
        "* weather = pd.read_sql(\"weather\", engine)\n",
        "\n",
        "#### OR load entire weather table with SQL\n",
        "* weather = pd.read_sql(\"SELECT * FROM weather\", engine)\n",
        "\n",
        "#### View the tables in the database\n",
        "* print(engine.table_names())"
      ],
      "metadata": {
        "id": "xr4SD5szEpDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **More comlex SQL queries**\n",
        "\n",
        "* SELECT DISTINCT [column names] FROM [table]\n",
        "* Remove duplicates - SELECT DISTINCT * FROM [table]\n",
        "* SELECT COUNT(*) FROM [table]\n",
        "* SELECT COUNT(DISTINCT [coumn_name] FROM [table]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OeNAss-LNC5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **JSON Files**\n",
        "\n",
        "* Javascript Object Notation\n",
        "* not tabular\n",
        "* records don't need to have same set of attributes\n",
        "* data organised into collections of objects\n",
        "* objects are collections of attribute-value pairs\n",
        "* nested JSON: objects within objests\n",
        "\n",
        "### **Load JSON**\n",
        "\n",
        "* pd.read_json\n",
        "* dtype - specify data types\n",
        "* orient - uncommon data layouts\n",
        "* record orientation\n",
        "* column orientation\n",
        "* split orientation\n",
        "\n",
        "### **Load JSON from APIs**\n",
        "\n",
        "* requests.get(url_string)\n",
        "* params - dictionary of parameters and values\n",
        "* headers - dictionary of user authentication\n",
        "* result: respose object containing data and metadata\n",
        "* response.json () - returns just JSON data\n",
        "* response.json () - returns just a dictionary\n",
        "* load response.json() to df with pd.DataFrame\n",
        "* read_json will not work\n",
        "\n",
        "\n",
        "### **E.g. Call Yelp API**\n",
        "* api_url = 'https://api.yelp.com/v3/businesses/search'\n",
        "\n",
        "--set up parameter dictionary according to api documentation\n",
        "\n",
        "* params = {'term' : 'bookstore','location' : 'San Francisco'}\n",
        "\n",
        "--set up header dictionary w/ API key according to documentation\n",
        "\n",
        "* headers = {'Authorization' : 'Bearer {}'.format(api_key)}\n",
        "\n",
        "-- call the API\n",
        "* response = requests.get(api_url, params = params, headers = headers)\n",
        "\n",
        "-- parse the response - isolate json data from response object - required informnaton is in a list under 'businesses' key\n",
        "\n",
        "* data = response.json()\n",
        "\n",
        "-- load businesses data to a dataframe\n",
        "\n",
        "* bookstores = pd.Dataframe(data['businesses'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MxjjepUlrub4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nested JSON**\n",
        "\n",
        "* JSONs - contain objects with attribute-value pairs\n",
        "* Nested JSON - value is itself an object\n",
        "* pandas.io.json\n",
        "  * needs own import\n",
        "* json_normalize()\n",
        "  * dictionary / list of dictionaries like pd.DataFrame\n",
        "  * returns flattened dataframe\n",
        "  * default flattened column name pattern: attribute.nestedattribute\n",
        "  * choose different seperator with sep argument\n",
        "\n",
        "### **Load Nested JSON Data**\n",
        "\n",
        "* from pandas.io.json import json_normalize\n",
        "\n",
        "* api_url = 'https://api.yelp.com/v3/businesses/search'\n",
        "\n",
        "\n",
        "--set up parameter dictionary according to api documentation\n",
        "\n",
        "* params = {'term' : 'bookstore','location' : 'San Francisco'}\n",
        "\n",
        "--set up header dictionary w/ API key according to documentation\n",
        "\n",
        "* headers = {'Authorization' : 'Bearer {}'.format(api_key)}\n",
        "\n",
        "-- call the API\n",
        "* response = requests.get(api_url, params = params, headers = headers)\n",
        "\n",
        "-- parse the response - isolate json data from response object - required informnaton is in a list under 'businesses' key\n",
        "\n",
        "* data = response.json()\n",
        "\n",
        "-- flatten data and load businesses data to a dataframe with _ seperators\n",
        "\n",
        "* bookstores = json_normalize(data['businesses'], sep= '_')\n",
        "* print(list(bookstores))\n",
        "\n",
        "\n",
        "### **Deeply Nested JSON Data**\n",
        "\n",
        "* json_normalize()\n",
        "  * record_path - string/list of string attibutes to nested data\n",
        "  * meta - list of other attributes to load to dataframe\n",
        "  * meta_prefix - string to prefix to meta column names\n",
        "\n",
        "#### **Load deeply nested data**\n",
        "\n",
        "-- flatten categories data,bring in business details\n",
        "\n",
        "* df = json_normalize(data['businesses'],\n",
        "* sep = '_',\n",
        "* record_path = 'categories',\n",
        "* meta = ['name', 'alias', 'rating',\n",
        "* ['coordinates' , 'latitude'],\n",
        "* ['coordinates' ,  'longitude']],\n",
        "* meta_prefix = 'biz_')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zkAcw6UeYf1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Combining Multiple Datasets**\n",
        "\n",
        "### **Concatenating**\n",
        "* add rows from one df to another\n",
        "* pd.concat(df1, df2)\n",
        "* ignore_index=True - relabel rows\n",
        "\n",
        "### **Merging**\n",
        "* combining datasets to add related columns\n",
        "* datasets have key columns with common values\n",
        "* pandas version of SQL join\n",
        "* merge()\n",
        "  * both a pandas function and a dataframe method\n",
        "* df.merge() arguments\n",
        "  * second dataframe to merge\n",
        "  * columns to merge on\n",
        "    * on if nammes are the same in both dataframes\n",
        "    * left_on and right_on if key names differ\n",
        "    * key columns must be same data type\n",
        "* defaulkt merge(): returnds only values in both datasents\n",
        "* one record for each value match\n",
        "* multiple matches -= multiple records\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ce7_rVMZfa7m"
      }
    }
  ]
}