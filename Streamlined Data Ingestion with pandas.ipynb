{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8TW1a/6vaio83MMixbx23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmalaraj77/Python/blob/main/Streamlined%20Data%20Ingestion%20with%20pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Streamlined Data Ingestion with pandas**\n"
      ],
      "metadata": {
        "id": "AP6li-VVaAZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Notes**\n",
        "\n",
        "### **Plot the total number of tax returns by income group**\n",
        "* counts = data.groupby(\"agi_stub\").N1.sum()\n",
        "* counts.plot.bar()\n",
        "* plt.show()\n",
        "\n",
        "### **View counts of dependents and tax returns by income level**\n",
        "* print(data.groupby(\"agi_stub\").sum())\n",
        "\n",
        "### **check if 2 dfs are equal**\n",
        "* tax_data_v1.equals(tax_data_v2)\n",
        "\n",
        "###**find data with NA values**\n",
        "* print(tax_data[tax_data.zipcode.isna()])\n",
        "\n"
      ],
      "metadata": {
        "id": "wnO2HUkJdeIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Flat Files**\n",
        "* Load pandas\n",
        "* Import files\n",
        "* Use sep = '\\t' for TSV\n"
      ],
      "metadata": {
        "id": "JZHQ_r8KapMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rOJUkLBbZcs5"
      },
      "outputs": [],
      "source": [
        "#  load pandas and df\n",
        "import pandas as pd\n",
        "\n",
        "vermont_url = 'https://assets.datacamp.com/production/repositories/4412/datasets/61bb27bf939aac4344d4f446ce6da1d1bf534174/vt_tax_data_2016.csv'\n",
        "free_code_camp_url = 'https://assets.datacamp.com/production/repositories/4412/datasets/fdb113aa942a0e0ad5c155b2f04784886f0038c9/fcc-new-coder-survey.xlsx'\n",
        "nyc_weather_url = 'https://github.com/nirmalaraj77/datasets/blob/main/data.db'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modify flat file imports**\n",
        "\n",
        "### **limit columns - usecols**\n",
        "* accepts list of col numbers, names or function\n",
        "\n",
        "### **limit rows - nrows and skiprows**\n",
        "* accepts list of row numbers, number of rows or function\n",
        "* set header =None so pandas knows there are no column names\n",
        "* get rows 1000 to 1500\n",
        "* df = pd.read_csv ('xxx.csv', nrows = 1000, skiprows = 1000, header=None)\n",
        "\n",
        "### **assign column names**\n",
        "* names argument\n",
        "* list MUST include name for every column\n",
        "* can get list from previous df to reuse -> col_names = list(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkpwYlHgelD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load vermont db\n",
        "import pandas as pd\n",
        "vermont = pd.read_csv(vermont_url)\n",
        "\n",
        "# find shape\n",
        "print(vermont.shape)\n",
        "\n",
        "# get col names\n",
        "col_names = list(vermont)\n",
        "print(col_names)\n",
        "\n",
        "# load 1000 - 1250 rows with column names\n",
        "vermont_1000_1250 = pd.read_csv(vermont_url, nrows = 251, skiprows = 1000, header=None, names = col_names)\n",
        "print(vermont_1000_1250.head())\n"
      ],
      "metadata": {
        "id": "gvJPMnbmmE3h",
        "outputId": "0a776aa2-545c-4944-aeaa-f628bcb8fd98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1476, 147)\n",
            "['STATEFIPS', 'STATE', 'zipcode', 'agi_stub', 'N1', 'mars1', 'MARS2', 'MARS4', 'PREP', 'N2', 'NUMDEP', 'TOTAL_VITA', 'VITA', 'TCE', 'VITA_EIC', 'RAL', 'RAC', 'ELDERLY', 'A00100', 'N02650', 'A02650', 'N00200', 'A00200', 'N00300', 'A00300', 'N00600', 'A00600', 'N00650', 'A00650', 'N00700', 'A00700', 'N00900', 'A00900', 'N01000', 'A01000', 'N01400', 'A01400', 'N01700', 'A01700', 'SCHF', 'N02300', 'A02300', 'N02500', 'A02500', 'N26270', 'A26270', 'N02900', 'A02900', 'N03220', 'A03220', 'N03300', 'A03300', 'N03270', 'A03270', 'N03150', 'A03150', 'N03210', 'A03210', 'N03230', 'A03230', 'N03240', 'A03240', 'N04470', 'A04470', 'A00101', 'N17000', 'A17000', 'N18425', 'A18425', 'N18450', 'A18450', 'N18500', 'A18500', 'N18800', 'A18800', 'N18300', 'A18300', 'N19300', 'A19300', 'N19500', 'A19500', 'N19530', 'A19530', 'N19550', 'A19550', 'N19570', 'A19570', 'N19700', 'A19700', 'N20800', 'A20800', 'n21020', 'a21020', 'N04800', 'A04800', 'N05800', 'A05800', 'N09600', 'A09600', 'N05780', 'A05780', 'N07100', 'A07100', 'N07300', 'A07300', 'N07180', 'A07180', 'N07230', 'A07230', 'N07240', 'A07240', 'N07220', 'A07220', 'N07260', 'A07260', 'N09400', 'A09400', 'N85770', 'A85770', 'N85775', 'A85775', 'N09750', 'A09750', 'N10600', 'A10600', 'N59660', 'A59660', 'N59720', 'A59720', 'N11070', 'A11070', 'N10960', 'A10960', 'N11560', 'A11560', 'N06500', 'A06500', 'N10300', 'A10300', 'N85530', 'A85530', 'N85300', 'A85300', 'N11901', 'A11901', 'N11902', 'A11902']\n",
            "   STATEFIPS STATE  zipcode  agi_stub   N1  mars1  MARS2  MARS4  PREP   N2  \\\n",
            "0         50    VT     5730         4   20      0      0      0    40   40   \n",
            "1         50    VT     5730         5   30      0     30      0     0   70   \n",
            "2         50    VT     5730         6    0      0      0      0     0    0   \n",
            "3         50    VT     5732         1  200    150     30     30   100  260   \n",
            "4         50    VT     5732         2  120     70     30      0    60  200   \n",
            "\n",
            "   ...  N10300  A10300  N85530  A85530  N85300  A85300  N11901  A11901  \\\n",
            "0  ...       0       0       0       0       0       0       0       0   \n",
            "1  ...      30    1046       0       0       0       0       0       0   \n",
            "2  ...       0       0       0       0       0       0       0       0   \n",
            "3  ...     110     104       0       0       0       0      20      20   \n",
            "4  ...     110     294       0       0       0       0       0       0   \n",
            "\n",
            "   N11902  A11902  \n",
            "0       0       0  \n",
            "1      20      71  \n",
            "2       0       0  \n",
            "3     160     250  \n",
            "4     110     215  \n",
            "\n",
            "[5 rows x 147 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Error Handling**\n",
        "\n",
        "###**Specify data types**\n",
        "\n",
        "* dtype - takes dictionary of column name and date type\n",
        "* non-standard dtypes like pandas categories must be passed in quotations\n",
        "\n",
        "###**Customize missing data values**\n",
        "\n",
        "* na_values - takes single value, list or dict of colmns and values\n",
        "\n",
        "###**Lines with errors**\n",
        "\n",
        "* error_bad_lines=False - skip unparsable records\n",
        "* warn_bad_lines=True - see messages when records are skipped\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NWxwOP6Uo1Gg"
      }
    }
  ]
}