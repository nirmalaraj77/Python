{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJWUpazG6ioZTHR3WNJ+Mh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmalaraj77/Python/blob/main/Cleaning_Data_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cleaning Data in Python**\n",
        "\n",
        "* .info()\n",
        "* .describe()\n",
        "* assert\n",
        "* new unnamed index column - index_col = 'Unnamed: 0'\n",
        "\n"
      ],
      "metadata": {
        "id": "L4EZ2dCUmFjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import practise datasets\n",
        "import pandas as pd\n",
        "\n",
        "airlines = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/refs/heads/main/airlines_final.csv', index_col = 'Unnamed: 0')\n",
        "banking = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/refs/heads/main/banking_dirty.csv', index_col = 'Unnamed: 0')\n",
        "ride_sharing = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/refs/heads/main/ride_sharing_new.csv', index_col = 'Unnamed: 0')\n",
        "restaurants = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/refs/heads/main/restaurants_L2.csv', index_col = 'Unnamed: 0')\n",
        "restaurants_new = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/refs/heads/main/restaurants_L2_dirty.csv', index_col = 'Unnamed: 0')"
      ],
      "metadata": {
        "id": "oLyqa7dimYCS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **String to Integers**\n",
        "\n",
        "###Remove '£' from Revenue column\n",
        "* Sales['Revenue'] = Sales['Revenue'].str.strip('£')\n",
        "\n",
        "###Convert Revenue column to integer\n",
        "* Sales['Revenue'] = Sales['Revenue'].astype('int')\n",
        "\n",
        "###Verify datatype\n",
        "* assert Sales['Revenue'].dtype == 'int'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g0AB6xEZucsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Numeric to Categorical**\n",
        "\n",
        "###Convert to category\n",
        "* df['col_name'] = df['col_name'].astype('category')\n",
        "\n"
      ],
      "metadata": {
        "id": "h0sDzIT3wNuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the information of ride_sharing\n",
        "print(ride_sharing.info())\n",
        "\n",
        "# Print summary statistics of user_type column\n",
        "print(ride_sharing['user_type'].describe())\n",
        "\n",
        "# Convert user_type from integer to category\n",
        "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')\n",
        "\n",
        "# Write an assert statement confirming the change\n",
        "assert ride_sharing['user_type_cat'].dtype == 'category'\n",
        "\n",
        "# Print new summary statistics\n",
        "print(ride_sharing['user_type_cat'].describe())"
      ],
      "metadata": {
        "id": "hOzzBodsy_47",
        "outputId": "8db9b69d-206d-4431-ccc5-7baebdfc8a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 25760 entries, 0 to 25759\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   duration         25760 non-null  object\n",
            " 1   station_A_id     25760 non-null  int64 \n",
            " 2   station_A_name   25760 non-null  object\n",
            " 3   station_B_id     25760 non-null  int64 \n",
            " 4   station_B_name   25760 non-null  object\n",
            " 5   bike_id          25760 non-null  int64 \n",
            " 6   user_type        25760 non-null  int64 \n",
            " 7   user_birth_year  25760 non-null  int64 \n",
            " 8   user_gender      25760 non-null  object\n",
            " 9   duration_trim    25760 non-null  object\n",
            " 10  duration_time    25760 non-null  int64 \n",
            "dtypes: int64(6), object(5)\n",
            "memory usage: 2.4+ MB\n",
            "None\n",
            "count    25760.000000\n",
            "mean         2.008385\n",
            "std          0.704541\n",
            "min          1.000000\n",
            "25%          2.000000\n",
            "50%          2.000000\n",
            "75%          3.000000\n",
            "max          3.000000\n",
            "Name: user_type, dtype: float64\n",
            "count     25760\n",
            "unique        3\n",
            "top           2\n",
            "freq      12972\n",
            "Name: user_type_cat, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip duration of minutes\n",
        "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes')\n",
        "\n",
        "# Convert duration to integer\n",
        "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
        "\n",
        "# Write an assert statement making sure of conversion\n",
        "assert ride_sharing['duration_time'].dtype == 'int'\n",
        "\n",
        "# Print formed columns and calculate average ride duration\n",
        "print(ride_sharing[['duration','duration_trim','duration_time']])\n",
        "print(ride_sharing['duration_time'].mean())"
      ],
      "metadata": {
        "id": "Za_LsjdUzCPk",
        "outputId": "ea5d87ac-7c13-4e70-a732-11f9f1190efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         duration duration_trim  duration_time\n",
            "0      12 minutes           12              12\n",
            "1      24 minutes           24              24\n",
            "2       8 minutes            8               8\n",
            "3       4 minutes            4               4\n",
            "4      11 minutes           11              11\n",
            "...           ...           ...            ...\n",
            "25755  11 minutes           11              11\n",
            "25756  10 minutes           10              10\n",
            "25757  14 minutes           14              14\n",
            "25758  14 minutes           14              14\n",
            "25759  29 minutes           29              29\n",
            "\n",
            "[25760 rows x 3 columns]\n",
            "11.389052795031056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Out of range dates**\n",
        "\n",
        "* import datetime as dt\n",
        "* today_date = dt.date.today()\n",
        "* find dates in the future\n",
        "* df['subs_date'] > today_date"
      ],
      "metadata": {
        "id": "Z1PAwk2_2LrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "today_date = dt.date.today()\n",
        "today_date\n",
        "birthday = dt.date(1999, 10, 2)\n",
        "today_date < birthday"
      ],
      "metadata": {
        "id": "538ozAVo2wn6",
        "outputId": "c4938121-7972-4798-c061-20e71762ac4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deal with out of range data**\n",
        "\n",
        "* drop\n",
        "* setting custom minimum and maximums\n",
        "* treat as missing and impute\n",
        "* setting custom value depending on business assumption\n",
        "\n",
        "### Drop values using filtering\n",
        "* movies = movies['rating'] <= 5\n",
        "\n",
        "### Drop values using .drop\n",
        "movies.drop(movies[movies['rating'] > 5].index, inplace = True)\n",
        "\n",
        "### Set custom maximum value\n",
        "* movies.loc[movies['rating'] > 5, 'rating'] = 5\n",
        "\n",
        "### Convert to date\n",
        "* import datetime as dt\n",
        "* movie['signup'] = pd.to_datetime(movie['signup']).dt.date\n",
        "\n",
        "\n",
        "### Drop future dates using filtering or .drop\n",
        "\n",
        "### Hardcode dates with upper limit\n",
        "today_date = dt.date.today()\n",
        "* movies.loc[movies['signup'] > today_date, 'signup'] = today_date\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QE_lwxyn4l8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Uniqeness Constraints**\n",
        "\n",
        "* **Subsetting on metadata and keeping all duplicate records gives you a better bird-eye's view over your data and how to duplicate it**\n",
        "\n",
        "### Find Duplicates\n",
        "\n",
        "* .duplicated()\n",
        "* True for duplicated and False for non-duplicated\n",
        "* subset: list of column names to check for duplication\n",
        "* keep: whether to keep 'first', 'last' or all ('False') duplicate values\n",
        "* .sort_values(by = 'col_name')\n",
        "\n",
        "### Drop full duplicates\n",
        "\n",
        "* .drop_duplicates()\n",
        "* subset: list of column names to check for duplication\n",
        "* keep: whether to keep 'first', 'last' or all ('False') duplicate values\n",
        "* inplace: Drop duplicated directly in df ('True')\n",
        "\n",
        "### Drop partial duplicates\n",
        "\n",
        "* Group by column names and produce statistical summaries\n",
        "* .goupby() and .agg()\n",
        "* .reset_index() - numbered indices in final output\n",
        "* column_names = ['first_name', 'last_name', 'addres']\n",
        "* summaries = {'height' : 'max', 'weight' : 'mean'}\n",
        "* height_weight = height_weight.groupby(by = column_names).agg(summaries).reset_index()\n",
        "*\n",
        "\n",
        "#### Find duplicates\n",
        "* duplicates = ride_sharing.duplicated(subset = 'ride_id', keep = False)\n",
        "\n",
        "#### Sort your duplicated rides\n",
        "* duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
        "\n",
        "#### Print relevant columns\n",
        "* print(duplicated_rides[['ride_id','duration','user_birth_year']])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ulvBBORO4_VA"
      }
    }
  ]
}