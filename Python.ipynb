{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNox1QHn+oUyakUyd9pUoK6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmalaraj77/Python/blob/main/Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**JOINING DATA WITH PANDAS**"
      ],
      "metadata": {
        "id": "cs6FQCTYDzu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "census = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/census.p')\n",
        "\n",
        "wards = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/ward.p')\n",
        "\n",
        "licenses = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/licenses.p')\n",
        "\n",
        "biz_owners = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/business_owners.p')\n",
        "\n",
        "cal = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/calendar.p')\n",
        "\n",
        "ridership = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/ridership.p')\n",
        "\n",
        "stations = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/stations.p')\n",
        "\n",
        "zip_demo = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/zip_demo.p')\n",
        "\n",
        "land_use = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/land_use.p')\n",
        "\n",
        "actors = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/actors_movies.csv.xls')\n",
        "\n",
        "movies = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/movies.p')\n",
        "\n",
        "taglines = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/taglines.p')\n",
        "\n",
        "financials = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/financials.p')\n",
        "\n",
        "movie_to_genres = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/movie_to_genres.p')\n",
        "\n",
        "crews = pd.read_pickle('https://raw.githubusercontent.com/nirmalaraj77/datasets/main/crews.p')\n",
        "\n",
        "gdp = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/2aa0493ec6cc102715dbfc5fdcdf64c576049b2c/WorldBank_GDP.csv.xls')\n",
        "\n",
        "sp500 = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/2aa0493ec6cc102715dbfc5fdcdf64c576049b2c/S&P500.csv.xls')\n",
        "\n",
        "pop = pd.read_csv('https://raw.githubusercontent.com/nirmalaraj77/datasets/2aa0493ec6cc102715dbfc5fdcdf64c576049b2c/WorldBank_POP.csv.xls')"
      ],
      "metadata": {
        "id": "mYNFe-b-D7lS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Notes**\n",
        "\n",
        "* df.shape\n",
        "\n",
        "* df.columns\n",
        "\n",
        "* df['column'].value_counts\n",
        "\n",
        "* df[['column']].head()\n",
        "\n",
        "* pd.read_pickle\n",
        "\n",
        "* \\ line continuation as single line\n",
        "\n",
        "* group by column and aggregate - grouped_df = df.groupby('column1').agg({'column2':'count'})\n",
        "\n",
        "* group by column and sum - grouped_df = df.groupby('column1').sum\n",
        "\n",
        "* count null - .isnull() method to return Boolean index if column is null and .sum() method to count Boolean index for number of True values - number_of_missing_df = df['col'].isnull().sum()\n",
        "\n",
        "* group multiple df columns - enter as list to .groupby() method\n",
        "\n",
        "* sort desending\n",
        "* sorted_df = df.sort_values('columns', ascending=False)\n",
        "\n",
        "* sort multiple df columns -  enter as list to .sort_values() method\n",
        "\n",
        "* ascending argument accepts a list of Booleans\n",
        "\n",
        "* if joining on different column names - left_on = 'col1', right_on = 'col2'\n",
        "\n",
        "* **Create an index that returns true if name_1 or name_2 are null\n",
        "m = ((iron_1_and_2['name_1'].isnull()) |\n",
        "     (iron_1_and_2['name_2'].isnull()))**\n",
        "\n",
        "* set index - pd.read_csv(csv_file, index_col=['col1', 'col2'])\n",
        "\n",
        "* when sub-selecting the columns, input the desired columns as a list - new_df = df[['col1', 'col2', 'col3']]\n",
        "\n",
        "* Using .isin() filter - popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]"
      ],
      "metadata": {
        "id": "8Wv1mDLdj21K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Inner Joins**\n",
        "\n",
        "* Merge on common column name\n",
        "\n",
        "* only returns matching values in both tables\n",
        "\n",
        "* columns in 1st table comes first\n",
        "\n",
        "* _x and _y - generated if common columns exist\n",
        "\n",
        "* suffixes = argumnent to control _x and _y naming\n"
      ],
      "metadata": {
        "id": "AQ5UGOarD8FK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shapes (number of rows and columns) and column names\n",
        "print('wards: ' , wards.shape , wards.columns)\n",
        "print('census: ' , census.shape, census.columns)"
      ],
      "metadata": {
        "id": "cIXvr2cj1uoV",
        "outputId": "5be24c2c-7978-4add-bfd2-51aa5a5ee614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wards:  (50, 4) Index(['ward', 'alderman', 'address', 'zip'], dtype='object')\n",
            "census:  (50, 6) Index(['ward', 'pop_2000', 'pop_2010', 'change', 'address', 'zip'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge wards and census with suffixes\n",
        "wards_census = wards.merge(census, on='ward', suffixes = ('_ward', '_census'))\n",
        "\n",
        "print(wards_census.shape)\n",
        "print (wards_census.columns)"
      ],
      "metadata": {
        "id": "NvElgDCw3H_0",
        "outputId": "6c646395-d6b1-4994-f958-ce3cb819b401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 9)\n",
            "Index(['ward', 'alderman', 'address_ward', 'zip_ward', 'pop_2000', 'pop_2010',\n",
            "       'change', 'address_census', 'zip_census'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count value of the change column\n",
        "print(wards_census['change'].value_counts())"
      ],
      "metadata": {
        "id": "djbp20aI7kVk",
        "outputId": "078a453f-8727-4476-eb77-7fdfba91a6ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change\n",
            "-8%     4\n",
            "-6%     4\n",
            "-4%     4\n",
            "-5%     3\n",
            "3%      3\n",
            "-17%    2\n",
            "-13%    2\n",
            "-11%    2\n",
            "-14%    2\n",
            "-3%     2\n",
            "0%      2\n",
            "6%      2\n",
            "-24%    2\n",
            "5%      2\n",
            "-33%    1\n",
            "-20%    1\n",
            "1%      1\n",
            "-9%     1\n",
            "-10%    1\n",
            "-16%    1\n",
            "8%      1\n",
            "-1%     1\n",
            "-7%     1\n",
            "12%     1\n",
            "31%     1\n",
            "-15%    1\n",
            "-18%    1\n",
            "-2%     1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**One-to-Many Relationships**\n",
        "\n",
        "* every row in left table is related to one or more in right table\n",
        "\n",
        "* resulting table has many rows from left table matching each value in right table\n",
        "\n"
      ],
      "metadata": {
        "id": "xAvnyEi3-4s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge wards with lecenses\n",
        "\n",
        "wards_licenses = wards.merge(licenses, on='ward')\n",
        "\n",
        "print(wards_licenses.shape)\n",
        "print(wards_licenses.head(10))"
      ],
      "metadata": {
        "id": "Ab9Qo8mpB5tb",
        "outputId": "76640696-9b15-416e-c42d-e3516ebfce98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 9)\n",
            "  ward            alderman                  address_x  zip_x account  aid  \\\n",
            "0    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   12024  NaN   \n",
            "1    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   14446  743   \n",
            "2    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   14624  775   \n",
            "3    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   14987  NaN   \n",
            "4    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   15642  814   \n",
            "5    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   16004  NaN   \n",
            "6    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   16497  638   \n",
            "7    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   16547  763   \n",
            "8    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   16662  763   \n",
            "9    1  Proco \"Joe\" Moreno  2058 NORTH WESTERN AVENUE  60647   16899  775   \n",
            "\n",
            "                   business                   address_y  zip_y  \n",
            "0       DIGILOG ELECTRONICS          1038 N ASHLAND AVE  60622  \n",
            "1          EMPTY BOTTLE INC      1035 N WESTERN AVE 1ST  60622  \n",
            "2      LITTLE MEL'S HOT DOG       2205 N CALIFORNIA AVE  60647  \n",
            "3        MR. BROWN'S LOUNGE      2301 W CHICAGO AVE 1ST  60622  \n",
            "4              Beat Kitchen     2000-2100 W DIVISION ST  60622  \n",
            "5   EL NUEVO NARANJO LOUNGE    2210 N MILWAUKEE AVE 1ST  60647  \n",
            "6               BELLA NOTTE            1374 W GRAND AVE  60642  \n",
            "7      PETE'S FOOD & LIQUOR     2556 W ARMITAGE AVE 1ST  60647  \n",
            "8  BUCK TOWN FOOD & LIQUORS        1950 N MILWAUKEE AVE  60647  \n",
            "9              JACK'S PLACE  2917 W ARMITAGE AVE  GROUN  60647  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the licenses and biz_owners table on account\n",
        "licenses_owners = licenses.merge(biz_owners, on='account')\n",
        "\n",
        "# Group the results by title then count the number of accounts\n",
        "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
        "\n",
        "# Sort the counted_df in desending order\n",
        "sorted_df = counted_df.sort_values('account', ascending=False)\n",
        "\n",
        "# Use .head() method to print the first few rows of sorted_df\n",
        "print(sorted_df.head())"
      ],
      "metadata": {
        "id": "eZ3thSqXDbv5",
        "outputId": "c962a837-77cb-4bc0-c489-e0929cf61a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 account\n",
            "title                   \n",
            "PRESIDENT           6259\n",
            "SECRETARY           5205\n",
            "SOLE PROPRIETOR     1658\n",
            "OTHER               1200\n",
            "VICE PRESIDENT       970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Merging Multiple DataFrames**\n",
        "\n",
        "* df1.merge(df2, on =['col', 'col'].merge(df2, on='col').merge(df3, on='col')...\n",
        "\n",
        "* use \\ python line continuation..\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YdIbPhjbF8rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the total rides through Wilson Station in July 2019 in weekdays\n",
        "\n",
        "# Merge the ridership, cal, and stations tables\n",
        "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
        "\t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
        "\n",
        "# Create a filter to filter ridership_cal_stations\n",
        "filter_criteria = ((ridership_cal_stations['month'] == 7)\n",
        "                   & (ridership_cal_stations['day_type'] == 'Weekday')\n",
        "                   & (ridership_cal_stations['station_name'] == 'Wilson'))\n",
        "\n",
        "# Use .loc and the filter to select for rides\n",
        "print ('Total rides through Wilson Station in July 2019 in weekdays were : '\\\n",
        " ,(ridership_cal_stations.loc[filter_criteria, 'rides'].sum()))\n",
        "\n"
      ],
      "metadata": {
        "id": "rFQFxOTsJ_IZ",
        "outputId": "f6dac9e3-152a-4abe-a124-e5a04010a664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rides through Wilson Station in July 2019 in weekdays were :  140005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
        "licenses_zip_ward = licenses.merge(zip_demo, on='zip') \\\n",
        "            \t\t\t.merge(wards, on='ward')\n",
        "\n",
        "# Print the results by alderman and show median income\n",
        "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))"
      ],
      "metadata": {
        "id": "cezPZAQYRvMz",
        "outputId": "88dba65f-df9d-44c1-98bb-9f106b46036e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             income\n",
            "alderman                           \n",
            "Ameya Pawar                 66246.0\n",
            "Anthony A. Beale            38206.0\n",
            "Anthony V. Napolitano       82226.0\n",
            "Ariel E. Reyboras           41307.0\n",
            "Brendan Reilly             110215.0\n",
            "Brian Hopkins               87143.0\n",
            "Carlos Ramirez-Rosa         66246.0\n",
            "Carrie M. Austin            38206.0\n",
            "Chris Taliaferro            55566.0\n",
            "Daniel \"Danny\" Solis        41226.0\n",
            "David H. Moore              33304.0\n",
            "Deborah Mell                66246.0\n",
            "Debra L. Silverstein        50554.0\n",
            "Derrick G. Curtis           65770.0\n",
            "Edward M. Burke             42335.0\n",
            "Emma M. Mitts               36283.0\n",
            "George Cardenas             33959.0\n",
            "Gilbert Villegas            41307.0\n",
            "Gregory I. Mitchell         24941.0\n",
            "Harry Osterman              45442.0\n",
            "Howard B. Brookins, Jr.     33304.0\n",
            "James Cappleman             79565.0\n",
            "Jason C. Ervin              41226.0\n",
            "Joe Moore                   39163.0\n",
            "John S. Arena               70122.0\n",
            "Leslie A. Hairston          28024.0\n",
            "Margaret Laurino            70122.0\n",
            "Marty Quinn                 67045.0\n",
            "Matthew J. O'Shea           59488.0\n",
            "Michael R. Zalewski         42335.0\n",
            "Michael Scott, Jr.          31445.0\n",
            "Michelle A. Harris          32558.0\n",
            "Michelle Smith             100116.0\n",
            "Milagros \"Milly\" Santiago   41307.0\n",
            "Nicholas Sposato            62223.0\n",
            "Pat Dowell                  46340.0\n",
            "Patrick Daley Thompson      41226.0\n",
            "Patrick J. O'Connor         50554.0\n",
            "Proco \"Joe\" Moreno          87143.0\n",
            "Raymond A. Lopez            33959.0\n",
            "Ricardo Munoz               31445.0\n",
            "Roberto Maldonado           68223.0\n",
            "Roderick T. Sawyer          32558.0\n",
            "Scott Waguespack            68223.0\n",
            "Susan Sadlowski Garza       38417.0\n",
            "Tom Tunney                  88708.0\n",
            "Toni L. Foulkes             27573.0\n",
            "Walter Burnett, Jr.         87143.0\n",
            "William D. Burns           107811.0\n",
            "Willie B. Cochran           28024.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge land_use and census and merge result with licenses including suffixes\n",
        "land_cen_lic = land_use.merge(census, on='ward') \\\n",
        "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
        "\n",
        "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
        "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'],\n",
        "                                   as_index=False).agg({'account':'count'})\n",
        "\n",
        "# Sort pop_vac_lic and print the results\n",
        "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'],\n",
        "                                             ascending=[False, True, True])\n",
        "\n",
        "# Print the top few rows of sorted_pop_vac_lic\n",
        "print(sorted_pop_vac_lic.head())"
      ],
      "metadata": {
        "id": "NfuQlAmXV3NS",
        "outputId": "99ce986a-7ba3-4f10-bf5a-9e0818cc617f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ward  pop_2010  vacant  account\n",
            "47    7     51581      19       80\n",
            "12   20     52372      15      123\n",
            "1    10     51535      14      130\n",
            "16   24     54909      13       98\n",
            "7    16     51954      13      156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Left Join**\n",
        "\n",
        "* all rows from left table and only matching rows from right table\n",
        "\n",
        "* null values created for non-matches\n",
        "\n",
        "* how = 'left'\n",
        "\n",
        "* .isnull() method to return Boolean index if column is null\n",
        "\n",
        "* .sum() method to count Boolean index for number of True values\n",
        "\n",
        "* number_of_missing_df = df['col'].isnull().sum()\n",
        "\n",
        "* one-to-many - if rows in left table match multiple rows in right table - all of those rows will be returned\n",
        "\n",
        ". Therefore, the returned rows must be equal to if not greater than the left table. Knowing what to expect is useful in troubleshooting any suspicious merges.\n",
        "\n"
      ],
      "metadata": {
        "id": "hQGUwXsjWf4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Left join movies and taglines\n",
        "\n",
        "movies_taglines = movies.merge(taglines, on='id', how='left')\n",
        "\n",
        "print(movies_taglines.head())"
      ],
      "metadata": {
        "id": "K-vqvvZKYpUU",
        "outputId": "bdf1909b-48f1-4a47-97ba-16628e2032db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id                 title  popularity release_date  \\\n",
            "0    257          Oliver Twist   20.415572   2005-09-23   \n",
            "1  14290  Better Luck Tomorrow    3.877036   2002-01-12   \n",
            "2  38365             Grown Ups   38.864027   2010-06-24   \n",
            "3   9672              Infamous    3.680896   2006-11-16   \n",
            "4  12819       Alpha and Omega   12.300789   2010-09-17   \n",
            "\n",
            "                                           tagline  \n",
            "0                                              NaN  \n",
            "1             Never underestimate an overachiever.  \n",
            "2  Boys will be boys. . . some longer than others.  \n",
            "3          There's more to the story than you know  \n",
            "4                           A Pawsome 3D Adventure  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the movies table with the financials table with a left join\n",
        "movies_financials = movies.merge(financials, on='id', how='left')\n",
        "\n",
        "# Count the number of rows in the budget column that are missing\n",
        "number_of_missing_fin = movies_financials['budget'].isnull().sum()\n",
        "\n",
        "# Print the number of movies missing financials\n",
        "print(number_of_missing_fin)\n",
        "\n"
      ],
      "metadata": {
        "id": "4Rpdx-CZqBYG",
        "outputId": "f4eb3623-6e67-4baf-832f-58f61dc53da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Right Join**\n",
        " * all rows from right table and only matching rows from left table\n",
        "\n",
        " * mirror opposite of left join\n",
        "\n",
        " * how = 'right'"
      ],
      "metadata": {
        "id": "6ePcjNUsF-Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gasHeHjQJcSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Outer Join**\n",
        "\n",
        "* all rows returned from both tables\n",
        "\n",
        "* null results whrn no match\n",
        "\n",
        "* how = 'outer'"
      ],
      "metadata": {
        "id": "X3azQmz7G-MX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Self Join - Merging a Table to Itself**\n",
        "\n",
        "* Same as other joins\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g3tEiNOqow3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the crews table to itself\n",
        "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
        "                                suffixes=('_dir','_crew'))\n",
        "\n",
        "# Create a boolean index to select the appropriate rows\n",
        "boolean_filter = ((crews_self_merged['job_dir'] == 'Director') &\n",
        "                  (crews_self_merged['job_crew'] != 'Director'))\n",
        "direct_crews = crews_self_merged[boolean_filter]\n",
        "\n",
        "# Print the first few rows of direct_crews\n",
        "print(direct_crews.head())"
      ],
      "metadata": {
        "id": "VKhNfcUvOxPm",
        "outputId": "86b75437-edb2-4b0b-ed88-6a10bdbe9940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id department_dir   job_dir       name_dir department_crew  \\\n",
            "156  19995      Directing  Director  James Cameron         Editing   \n",
            "157  19995      Directing  Director  James Cameron           Sound   \n",
            "158  19995      Directing  Director  James Cameron      Production   \n",
            "160  19995      Directing  Director  James Cameron         Writing   \n",
            "161  19995      Directing  Director  James Cameron             Art   \n",
            "\n",
            "           job_crew          name_crew  \n",
            "156          Editor  Stephen E. Rivkin  \n",
            "157  Sound Designer  Christopher Boyes  \n",
            "158         Casting          Mali Finn  \n",
            "160          Writer      James Cameron  \n",
            "161    Set Designer    Richard F. Mays  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Merging on Indexes**\n",
        "\n",
        "* same as other joins\n",
        "\n",
        "* index columns will be returnd as index\n",
        "\n",
        "* new_df = df1.merge(df2, left_on='df1_index', left_index=True, right_on='df2_index', right_index=True)"
      ],
      "metadata": {
        "id": "Mm4XWBjXP2dK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Filtering Joins**\n",
        "\n",
        "* filter observations from one table based on whether or not they match an observation in another table\n",
        "\n",
        "###**Semi Join**\n",
        "\n",
        "* returns intersection - simmilar to inner join\n",
        "\n",
        "* return only columns from left table - NOT from right table\n",
        "\n",
        "* no deuplicate rows even if there is a one-to-many relationship\n",
        "\n",
        "* .isin  - returns Boolean\n",
        "\n",
        "* 1st step - inner join tables\n",
        "* genres_tracks = genres.merge(top_tracks, on = 'gid')\n",
        "\n",
        "* 2nd step - code to compare every gid in genres table to gid in genres_track table and return boolean with .isin\n",
        "genres['gid'].isin(genres_tracks['gid'])\n",
        "\n",
        "* 3rd step - subset top_genres with boolean resulet and combine\n",
        "* genres_tracks = genres.merge(top_tracks, on = 'gid')\n",
        "* top_genres = genres[genres['gid'].isin(genres_tracks['gid'])]\n",
        "\n",
        "##**Anti Join**\n",
        "\n",
        "* returns observations in left table not in the right table\n",
        "\n",
        "* return only columns from left table - NOT from right table\n",
        "\n",
        "* 1st step - left join tables, set indicator = True\n",
        "\n",
        "* indicator = True adds column called _merge (both, left only)\n",
        "\n",
        "* genres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\n",
        "\n",
        "* 2nd step - use the loc accessor and _merge column to select rows only in left table\n",
        "\n",
        "gid_list = genres_tracks.loc[genres_tracks['_merge] == 'left only', 'gid']\n",
        "\n",
        "* 3rd step - use isin to filter rows\n",
        "\n",
        "non_top_genres = genres[genres['gid'].isin(gid_list)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HM8lv1n4Afgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Concatenate Dataframes Vertically**\n",
        "\n",
        "* pandas.concat()\n",
        "\n",
        "* axis=0, vertical\n",
        "\n",
        "* ignore_index=True if index has no valuable information - index 0 to n-1\n",
        "\n",
        "* pd.concat ([table1, table2, table3], ignore_index=True)\n",
        "\n",
        "###**Set labels to original tables**\n",
        "\n",
        "* ignore_index=False - keys argument\n",
        "\n",
        "* results in multi-index table with label on 1st level\n",
        "\n",
        "* pd.concat ([table1, table2, table3], ignore_index=False, keys=[table1, table2, table3])\n",
        "\n",
        "###**Concatenate tables with different column names**\n",
        "\n",
        "* include all columns in different tables\n",
        "\n",
        "* sort argument will alphabetically sort\n",
        "\n",
        "* pd.concat ([table1, table2, table3], sort=True)\n",
        "\n",
        "* set join='inner' for only matching columns from different tables\n",
        "\n",
        "* default is 'outer'\n",
        "\n",
        "* sort has no effect whrn join='inner'\n",
        "\n",
        "* pd.concat ([table1, table2, table3], join='inner')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tvtopggHcugB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Validate and Verify**\n",
        "\n",
        "* columns may have duplicate data\n",
        "\n",
        "* unintentional one-to-many relationship\n",
        "\n",
        "* unintentional many-to-many relationship\n",
        "\n",
        "###**Validate Merge**\n",
        "\n",
        "* .merge(validate=None) - default\n",
        "\n",
        "* 'one_to_one'\n",
        "\n",
        "* 'one_to_many'\n",
        "\n",
        "* 'many_to_one'\n",
        "\n",
        "* 'many_to_many'\n",
        "\n",
        "* raises merge error\n",
        "\n",
        "###**Verify Concatenate**\n",
        "\n",
        "* only checks index\n",
        "\n",
        "* .concat(verify_integrity=False) - default\n",
        "\n",
        "* verify_integrity= True - raises value error\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bl4kssn-dOvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**merge_ordered()**\n",
        "\n",
        "* merge time-series and other ordered data\n",
        "\n",
        "* results are similar to standard merge method\n",
        "\n",
        "* default is outer join\n",
        "\n",
        "* results are sorted\n",
        "\n",
        "* pd.merge_ordered(df1, df2)\n",
        "\n",
        "* fill missing value with previous value - * forward fill\n",
        "\n",
        "* fill_method='ffill'\n",
        "\n",
        "* order is important when merging on more than 1 column\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cYx1BwxoUWr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use merge_ordered() to merge gdp and sp500, and forward fill missing values\n",
        "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='Year', right_on='Date',\n",
        "                             how='left',  fill_method='ffill')\n",
        "\n",
        "# Subset the gdp and returns columns\n",
        "gdp_returns = gdp_sp500[['GDP', 'Returns']]\n",
        "\n",
        "# Print gdp_returns correlation\n",
        "print (gdp_returns.corr())"
      ],
      "metadata": {
        "id": "Cq9TFNsvuZZw",
        "outputId": "2165ce3f-6e9c-48e1-c562-4409dc49005b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              GDP   Returns\n",
            "GDP      1.000000  0.040669\n",
            "Returns  0.040669  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**merge_asof()**\n",
        "\n",
        "* similar to merge_ordered left join\n",
        "\n",
        "* match nearest less than or equal value - not exact matches\n",
        "\n",
        "* merged 'on' columns must be sorted\n",
        "\n",
        "* pd.merge_asof(df1, df2)\n",
        "\n",
        "* direction='backward' - default\n",
        "\n",
        "* direction='forward' - matches greater than or equal to\n",
        "\n",
        "* direction='nearest'- nearest row in right table (forward or backwards)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9BCXwGFdB0Ap"
      }
    }
  ]
}